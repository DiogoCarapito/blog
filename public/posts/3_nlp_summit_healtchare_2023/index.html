<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NLP Summit Healthcare 2023 | diogo carapito</title>
<meta name=keywords content="NLP,healthcare,conference,John Snow Labs"><meta name=description content="This week I attended the NLP Summit Healthcare 2023, a free virtual event organized by the John Snow Labs.
It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.
1. Best practices when developing NLP models
Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:"><meta name=author content><link rel=canonical href=https://diogocarapito.com/posts/3_nlp_summit_healtchare_2023/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://diogocarapito.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://diogocarapito.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://diogocarapito.com/favicon-32x32.png><link rel=apple-touch-icon href=https://diogocarapito.com/apple-touch-icon.png><link rel=mask-icon href=https://diogocarapito.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://diogocarapito.com/posts/3_nlp_summit_healtchare_2023/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://diogocarapito.com/posts/3_nlp_summit_healtchare_2023/"><meta property="og:site_name" content="diogo carapito"><meta property="og:title" content="NLP Summit Healthcare 2023"><meta property="og:description" content="This week I attended the NLP Summit Healthcare 2023, a free virtual event organized by the John Snow Labs. It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.
1. Best practices when developing NLP models Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-07T22:18:37+01:00"><meta property="article:modified_time" content="2023-04-07T22:18:37+01:00"><meta property="article:tag" content="NLP"><meta property="article:tag" content="Healthcare"><meta property="article:tag" content="Conference"><meta property="article:tag" content="John Snow Labs"><meta property="og:image" content="https://diogocarapito.com/3_NLP-Summit-Healthcare-logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diogocarapito.com/3_NLP-Summit-Healthcare-logo.png"><meta name=twitter:title content="NLP Summit Healthcare 2023"><meta name=twitter:description content="This week I attended the NLP Summit Healthcare 2023, a free virtual event organized by the John Snow Labs.
It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.
1. Best practices when developing NLP models
Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://diogocarapito.com/posts/"},{"@type":"ListItem","position":2,"name":"NLP Summit Healthcare 2023","item":"https://diogocarapito.com/posts/3_nlp_summit_healtchare_2023/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NLP Summit Healthcare 2023","name":"NLP Summit Healthcare 2023","description":"This week I attended the NLP Summit Healthcare 2023, a free virtual event organized by the John Snow Labs. It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.\n1. Best practices when developing NLP models Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:\n","keywords":["NLP","healthcare","conference","John Snow Labs"],"articleBody":"This week I attended the NLP Summit Healthcare 2023, a free virtual event organized by the John Snow Labs. It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.\n1. Best practices when developing NLP models Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:\nTest your models! - why would you expect untested software to work? Test your models with real data and real use cases and assess it’s performance. Don’t reuse academic models in production - published research ≠ building reliable systems, testing and fine-tuning are essencial parts of developing a functional tool. Test beyond accuracy - Test for Robustness, Bias, Fairness, Toxicity, Efficiency, Safety. John Snow Labs developed NLP test to help with model testing beyond regular benchmarks. 2. Mitigating bias in healthcare language models Gaurav Kaushik from ScienceIO presented a talk about mitigating bias in healthcare language models and the importance of its evaluation. Performance benchmarks lack the statistical power, they aren’t well validated enough and don’t incentivize the use of biased systems.\nAlgorithmic bias Systematic and repeatable errors that yield unfair outcomes which benefit certain groups over others Healthcare LP systems will influence clinical outcomes and therefore will mitigate or exacerbate outcome disparities Selection Bias - data used in training the model does not represent real-world Label bias - mismatch between annotations and target, e.g. due to judgement, human error, or label ambiguity Training bias - models amplify biases in the training data Semantic bias - bias from input representations such as inappropriate word associations Demographic bias - improper sensitivity to race or gender, or impaired performance on attributes related to subgroups Domain Bias - error bias in medical subdomains, such as disease areas, which can impair generalization Check this article for further information: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\n3. Prototypical Networks for Interpretable Diagnosis Prediction Betty van Aken from DATEXIS Research Group presented a language model that makes predictions based on parts of the text that are similar to prototypical patients providing justifications that doctors understand. It uses a prototypical network with label-wise attention to find the most similar patients to the input text and then uses a transformer to predict the diagnosis. This is a great example of how NLP can be used in healthcare space and opens the door to a lot of interesting applications.\nCheck their demo and the paper here: This Patient Looks Like That Patient: Prototypical Networks for Interpretable Diagnosis Prediction from Clinical Text\n4. EHR-Safe: Generating High-Fidelity and Privacy-Preserving Synthetic Electronic Health Records AI in healthcare has important privacy concerns, especially when dealing with sensitive data like Electronic Health Records (EHR). Cloud AI Team suggested that one way to overcome this challenge is to generate high-fidelity, privacy-preserving synthetic EHR data. They proposed a generative modeling framework, EHR-Safe, that can generate highly realistic synthetic EHR data that are robust against privacy attacks.\nCheck their paper here: EHR-Safe: Generating high-fidelity and privacy-preserving synthetic electronic health records\n5. Some organizations that are doing interesting work in NLP in healthcare: John Snow Labs - organizer of the summit and creator of state-of-the-art NLP in healthcare, like NLP test and SparkNLP Discovery Lab - Lab funded by Elsevier, Vrije Universiteit Amsterdam and the University of Amsterdam that operates at the crossroads of Knowledge Representation, Machine Learning and Natural Language Processing. NeuralMed - a healthcare AI company that develops AI solutions for the healthcare industry. Science IO - transforms medical text into enriched data to build solutions that improve patient care. DATEXIS - Data Science and Text-based Information Systems (DATEXIS) group at Beuth University of Applied Sciences Berlin This is a list of some interesting projects that were presented at the summit:\nSpark NLP - an open source text processing library for Python, Java, and Scala. NLP test - a suit of tests to help mitigate bias for NLP models. BioMedLM - a GPT style language model trained on biomedical abstracts and papers. BioGPT - a pre-trained language models on the biomedical domain. ProtoPatient Demo - diagnostic predictions using clinical text and prototypical patients. Clinical IE - a Large Language Model for information extraction of Clinical Text Finally, I’ll share some of the articles that were cited in the talks:\nDataset Carto graphy: Mapping and Diagnosing Datasets with Training Dynamics Five sources of bias in natural language processing Beyond Accuracy: Behavioral Testing of NLP Models with CheckList Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics TruthfulQA: Measuring How Models Mimic Human Falsehoods This Patient Looks Like That Patient: Prototypical Networks for Interpretable Diagnosis Prediction from Clinical Text Physician Global Assessment (PGA) EHR-Safe: Generating High-Fidelity and Privacy-Preserving Synthetic Electronic Health Records Open AI Fine-tuning guide There were many more interesting sessions I didn’t describe here, visit https://www.nlpsummit.org/ if you want further information. I’ll be there next year for sure! Thanks for reading!\nP.S. Copilot helped writing this blog post. LLMs are amazing and I’m excited to see what the future holds for NLP!\n","wordCount":"858","inLanguage":"en","image":"https://diogocarapito.com/3_NLP-Summit-Healthcare-logo.png","datePublished":"2023-04-07T22:18:37+01:00","dateModified":"2023-04-07T22:18:37+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://diogocarapito.com/posts/3_nlp_summit_healtchare_2023/"},"publisher":{"@type":"Organization","name":"diogo carapito","logo":{"@type":"ImageObject","url":"https://diogocarapito.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diogocarapito.com/ accesskey=h title="diogo carapito (Alt + H)">diogo carapito</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diogocarapito.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://diogocarapito.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://diogocarapito.com/search/ title=Search><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">NLP Summit Healthcare 2023</h1><div class=post-meta><span title='2023-04-07 22:18:37 +0100 WEST'>April 7, 2023</span></div></header><figure class=entry-cover><img loading=eager src=https://diogocarapito.com/3_NLP-Summit-Healthcare-logo.png alt="NLP Summit Healthcare 2023"></figure><div class=post-content><p>This week I attended the <strong><a href=https://www.nlpsummit.org/>NLP Summit Healthcare 2023</a></strong>, a free virtual event organized by the <a href=https://www.johnsnowlabs.com/>John Snow Labs</a>.
It was a great event with a lot of interesting talks. I’ll share some of my key takeaways.</p><h2 id=1-best-practices-when-developing-nlp-models>1. Best practices when developing NLP models<a hidden class=anchor aria-hidden=true href=#1-best-practices-when-developing-nlp-models>#</a></h2><p>Presented in the opening keynote by Dr. David Gondek, Chief Data Scientist at John Snow Labs, he sumarized some best practices that i found interesting as I’m beginning my NLP journey:</p><ul><li><strong>Test your models!</strong> - why would you expect untested software to work? Test your models with real data and real use cases and assess it’s performance.</li><li><strong>Don’t reuse academic models in production</strong> - published research ≠ building reliable systems, testing and fine-tuning are essencial parts of developing a functional tool.</li><li><strong>Test beyond accuracy</strong> - Test for Robustness, Bias, Fairness, Toxicity, Efficiency, Safety. John Snow Labs developed <strong><a href=https://nlptest.org/>NLP test</a></strong> to help with model testing beyond regular benchmarks.</li></ul><h2 id=2-mitigating-bias-in-healthcare-language-models>2. Mitigating bias in healthcare language models<a hidden class=anchor aria-hidden=true href=#2-mitigating-bias-in-healthcare-language-models>#</a></h2><p>Gaurav Kaushik from ScienceIO presented a talk about <strong>mitigating bias</strong> in <strong>healthcare language models</strong> and the importance of its evaluation. <strong>Performance benchmarks</strong> lack the statistical power, they aren’t well validated enough and <strong>don’t incentivize the use of biased systems</strong>.</p><ul><li><strong>Algorithmic bias</strong><ul><li>Systematic and repeatable errors that yield unfair outcomes which benefit certain groups over others</li><li>Healthcare LP systems will influence clinical outcomes and therefore will mitigate or exacerbate outcome disparities</li></ul></li><li><strong>Selection Bias</strong> - data used in training the model does not represent real-world</li><li><strong>Label bias</strong> - mismatch between annotations and target, <em>e.g.</em> due to judgement, human error, or label ambiguity</li><li><strong>Training bias</strong> - models amplify biases in the training data</li><li><strong>Semantic bias</strong> - bias from input representations such as inappropriate word associations</li><li><strong>Demographic bias</strong> - improper sensitivity to race or gender, or impaired performance on attributes related to subgroups</li><li><strong>Domain Bias</strong> - error bias in medical subdomains, such as disease areas, which can impair generalization</li></ul><p>Check this article for further information: <a href=https://aclanthology.org/2020.acl-main.442.pdf>Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</a></p><h2 id=3-prototypical-networks-for-interpretable-diagnosis-prediction>3. Prototypical Networks for Interpretable Diagnosis Prediction<a hidden class=anchor aria-hidden=true href=#3-prototypical-networks-for-interpretable-diagnosis-prediction>#</a></h2><p><strong>Betty van Aken</strong> from <strong>DATEXIS Research Group</strong> presented a language model that <strong>makes predictions</strong> based on parts of the text that are <strong>similar to prototypical patients</strong> providing justifications that doctors understand.
It uses a prototypical network with label-wise attention to <strong>find the most similar patients to the input text</strong> and then uses a transformer to <strong>predict the diagnosis</strong>.
This is a great example of how NLP can be used in healthcare space and opens the door to a lot of interesting applications.</p><p>Check their <a href=https://protopatient.demo.datexis.com/>demo</a> and the paper here: <a href=https://aclanthology.org/2022.aacl-main.14.pdf>This Patient Looks Like That Patient: Prototypical Networks for Interpretable Diagnosis Prediction from Clinical Text</a></p><h2 id=4-ehr-safe-generating-high-fidelity-and-privacy-preserving-synthetic-electronic-health-records>4. EHR-Safe: Generating High-Fidelity and Privacy-Preserving Synthetic Electronic Health Records<a hidden class=anchor aria-hidden=true href=#4-ehr-safe-generating-high-fidelity-and-privacy-preserving-synthetic-electronic-health-records>#</a></h2><p>AI in healthcare has important <strong>privacy concerns</strong>, especially when dealing with <strong>sensitive data like Electronic Health Records</strong> (EHR). Cloud AI Team suggested that one way to overcome this challenge is to generate high-fidelity, privacy-preserving synthetic EHR data.
They proposed a generative modeling framework, EHR-Safe, that <strong>can generate highly realistic synthetic EHR data</strong> that are robust against privacy attacks.</p><p>Check their paper here: <a href=https://ai.googleblog.com/2022/12/ehr-safe-generating-high-fidelity-and.html>EHR-Safe: Generating high-fidelity and privacy-preserving synthetic electronic health records</a></p><h2 id=5-some-organizations-that-are-doing-interesting-work-in-nlp-in-healthcare>5. Some organizations that are doing interesting work in NLP in healthcare:<a hidden class=anchor aria-hidden=true href=#5-some-organizations-that-are-doing-interesting-work-in-nlp-in-healthcare>#</a></h2><ul><li><strong><a href=https://www.johnsnowlabs.com/>John Snow Labs</a></strong> - organizer of the summit and creator of state-of-the-art NLP in healthcare, like <a href=https://github.com/johnsnowlabs/nlptest>NLP test</a> and <a href=https://sparknlp.org/>SparkNLP</a></li><li><strong><a href=https://discoverylab.ai/>Discovery Lab</a></strong> - Lab funded by Elsevier, Vrije Universiteit Amsterdam and the University of Amsterdam that operates at the crossroads of Knowledge Representation, Machine Learning and Natural Language Processing.</li><li><strong><a href=https://www.neuralmed.ai/en>NeuralMed</a></strong> - a healthcare AI company that develops AI solutions for the healthcare industry.</li><li><strong><a href=https://www.science.io/>Science IO</a></strong> - transforms medical text into enriched data to build solutions that improve patient care.</li><li><strong><a href=https://github.com/DATEXIS>DATEXIS</a></strong> - Data Science and Text-based Information Systems (DATEXIS) group at Beuth University of Applied Sciences Berlin</li></ul><hr><p>This is a list of some interesting projects that were presented at the summit:</p><ul><li><strong><a href=https://sparknlp.org/>Spark NLP</a></strong> - an open source text processing library for Python, Java, and Scala.</li><li><strong><a href=https://nlptest.org/>NLP test</a></strong> - a suit of tests to help mitigate bias for NLP models.</li><li><strong><a href=https://huggingface.co/stanford-crfm/BioMedLM>BioMedLM</a></strong> - a GPT style language model trained on biomedical abstracts and papers.</li><li><strong><a href=https://huggingface.co/microsoft/biogpt>BioGPT</a></strong> - a pre-trained language models on the biomedical domain.</li><li><strong><a href=https://protopatient.demo.datexis.com/>ProtoPatient</a></strong> Demo - diagnostic predictions using clinical text and prototypical patients.</li><li><strong><a href=https://huggingface.co/datasets/mitclinicalml/clinical-ie>Clinical IE</a></strong> - a Large Language Model for information extraction of Clinical Text</li></ul><hr><p>Finally, I’ll share some of the <strong>articles</strong> that were cited in the talks:</p><ul><li><a href=https://arxiv.org/abs/2009.10795>Dataset Carto graphy: Mapping and Diagnosing Datasets with Training Dynamics</a></li><li><a href=https://compass.onlinelibrary.wiley.com/doi/10.1111/lnc3.12432>Five sources of bias in natural language processing</a></li><li><a href=https://aclanthology.org/2020.acl-main.442.pdf>Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</a></li><li><a href=https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00425/108201/Quantifying-Social-Biases-in-NLP-A-Generalization>Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics</a></li><li><a href=https://arxiv.org/pdf/2109.07958.pdf>TruthfulQA: Measuring How Models Mimic Human Falsehoods</a></li><li><a href=https://aclanthology.org/2022.aacl-main.14.pdf>This Patient Looks Like That Patient: Prototypical Networks for Interpretable Diagnosis Prediction from Clinical Text</a></li><li><a href=https://assesschild.com/physician-global-assessment>Physician Global Assessment (PGA)</a></li><li><a href=https://www.researchsquare.com/article/rs-2347130/v1>EHR-Safe: Generating High-Fidelity and Privacy-Preserving Synthetic Electronic Health Records</a></li><li><a href=https://platform.openai.com/docs/guides/fine-tuning>Open AI Fine-tuning guide</a></li></ul><hr><p>There were many more interesting sessions I didn’t describe here, visit <a href=https://www.nlpsummit.org/>https://www.nlpsummit.org/</a> if you want further information.
I’ll be there next year for sure!
Thanks for reading!</p><p>P.S. Copilot helped writing this blog post.
LLMs are amazing and I’m excited to see what the future holds for NLP!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://diogocarapito.com/tags/nlp/>NLP</a></li><li><a href=https://diogocarapito.com/tags/healthcare/>Healthcare</a></li><li><a href=https://diogocarapito.com/tags/conference/>Conference</a></li><li><a href=https://diogocarapito.com/tags/john-snow-labs/>John Snow Labs</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://diogocarapito.com/>diogo carapito</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>